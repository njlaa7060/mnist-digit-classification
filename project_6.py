# -*- coding: utf-8 -*-
"""project_6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AsKh7wRccmi3mB1uMx6_0mQpLqV4mUAk

# Data Loading and Preprocessing

> Add blockquote
"""

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize pixel values
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Split data into training and testing sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

print("Training samples:", x_train.shape[0])
print("Validation samples:", x_val.shape[0])
print("Testing samples:", x_test.shape[0])

"""# Baseline Model with Traditional Machine Learning Algorithms

1.   List item
2.   List item


"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.datasets import mnist

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Flatten the images
x_train_flat = x_train.reshape(x_train.shape[0], -1)
x_test_flat = x_test.reshape(x_test.shape[0], -1)

# Initialize and train logistic regression model
logreg = LogisticRegression(max_iter=100)
logreg.fit(x_train_flat, y_train)

# Predictions on test set
y_pred = logreg.predict(x_test_flat)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Other evaluation metrics
print(classification_report(y_test, y_pred))

"""#  Ensemble of Machine Learning Algorithms"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.datasets import mnist

# # Load MNIST dataset
# (x_train, y_train), (x_test, y_test) = mnist.load_data()

# # Flatten the images
# x_train_flat = x_train.reshape(x_train.shape[0], -1)
# x_test_flat = x_test.reshape(x_test.shape[0], -1)

# # Initialize individual models
# decision_tree = DecisionTreeClassifier()
# random_forest = RandomForestClassifier()
# svm = SVC(probability=True)  # Set probability=True for voting classifier

# # Train individual models
# decision_tree.fit(x_train_flat, y_train)
# svm.fit(x_train_flat, y_train)
# random_forest.fit(x_train_flat, y_train)


# # Initialize and train voting classifier
# voting_clf = VotingClassifier(estimators=[('dt', decision_tree), ('rf', random_forest), ('svm', svm)], voting='soft')
# voting_clf.fit(x_train_flat, y_train)

# # Predictions on test set
# y_pred_voting = voting_clf.predict(x_test_flat)

# # Evaluate ensemble model performance
# accuracy_voting = accuracy_score(y_test, y_pred_voting)
# print("Ensemble Model Accuracy:", accuracy_voting)

# # Other evaluation metrics
# print(classification_report(y_test, y_pred_voting))

# Flatten the images: transform each 28x28 image into a 784 element vector
x_train = x_train.reshape((x_train.shape[0], -1))  # Reshape from (60000, 28, 28) to (60000, 784)
x_test = x_test.reshape((x_test.shape[0], -1))     # Reshape from (10000, 28, 28) to (10000, 784)

x_train, x_test = x_train / 255.0, x_test / 255.0

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC()
}

for name, model in models.items():
    model.fit(x_train, y_train)  # Train model
    y_pred = model.predict(x_test)  # Predict on test data
    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy
    print(f"{name} accuracy: {accuracy:.2f}")

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import numpy as np

# Flatten the images: transform each 28x28 image into a 784 element vector
x_train = x_train.reshape((x_train.shape[0], -1))  # Reshape from (60000, 28, 28) to (60000, 784)
x_test = x_test.reshape((x_test.shape[0], -1))     # Reshape from (10000, 28, 28) to (10000, 784)

x_train, x_test = x_train / 255.0, x_test / 255.0

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(probability=True)  # Set probability=True for SVC to enable probability estimates
}

# Train individual models and make predictions
predictions = []
for name, model in models.items():
    model.fit(x_train, y_train)  # Train model
    y_pred = model.predict_proba(x_test)  # Predict probabilities on test data
    predictions.append(y_pred)  # Store predictions

# Combine predictions using averaging
average_pred = np.mean(predictions, axis=0)

# Take the class with highest average probability as the final prediction
ensemble_pred = np.argmax(average_pred, axis=1)

# Calculate accuracy of ensemble model
ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
print(f"Ensemble accuracy: {ensemble_accuracy:.2f}")

"""# Neural Network Model Design

"""